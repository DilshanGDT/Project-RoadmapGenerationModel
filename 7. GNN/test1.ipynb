{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97fd067d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "from sklearn.preprocessing import StandardScaler, MultiLabelBinarizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import torch\n",
    "from torch_geometric.data import Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a147282c",
   "metadata": {},
   "source": [
    "Graph Building Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "30f63182",
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_float(val):\n",
    "    try:\n",
    "        return float(val.replace('째 N','').replace('째 S','').replace('째 E','').replace('째 W','').strip())\n",
    "    except:\n",
    "        return 0.0  # or some default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18cacd17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_graph_from_json(json_path, distance_threshold_km=50):\n",
    "    data = json.load(open(json_path,'r',encoding='utf-8'))\n",
    "    # Build node lists\n",
    "    safari_nodes = []\n",
    "    location_nodes = {}  # name -> index\n",
    "    for s in data:\n",
    "        safari_nodes.append(s)\n",
    "        location_nodes.setdefault(s['extracted_features']['district'], None)\n",
    "\n",
    "    # map nodes to indices\n",
    "    idx = 0\n",
    "    node_index = {}  # key -> idx (for safari use title/id; for location use 'LOC:Name')\n",
    "    for s in safari_nodes:\n",
    "        key = f\"SAF:{s['id'] if 'id' in s else s['title']}\"\n",
    "        node_index[key] = idx; idx+=1\n",
    "    for loc in location_nodes.keys():\n",
    "        key = f\"LOC:{loc}\"\n",
    "        node_index[key] = idx; idx+=1\n",
    "\n",
    "    # features: numeric + tags multi-hot + TF-IDF of description (optional)\n",
    "    # numeric arrays\n",
    "    lat = []\n",
    "    lon = []\n",
    "    rating = []\n",
    "    review_count = []\n",
    "    descriptions = []\n",
    "    all_tags = []\n",
    "    safari_keys = []\n",
    "    for s in safari_nodes:\n",
    "        safari_keys.append(f\"SAF:{s.get('id', s['title'])}\")\n",
    "\n",
    "        lat.append(safe_float(s['extracted_features'].get('latitude', '0')))\n",
    "        lon.append(safe_float(s['extracted_features'].get('longitude', '0')))\n",
    "\n",
    "\n",
    "        rating.append(float(s.get('rating', 0.0)))\n",
    "        review_count.append(int(s.get('total_reviews', '0').replace(',', '')))\n",
    "\n",
    "        descriptions.append(s.get('description',''))\n",
    "        all_tags.append(s.get('tags', []))\n",
    "\n",
    "    # normalize numeric\n",
    "    num_feats = np.vstack([lat, lon, rating, np.log1p(review_count)]).T\n",
    "    num_feats = StandardScaler().fit_transform(num_feats)\n",
    "\n",
    "    # tags multi-hot\n",
    "    mlb = MultiLabelBinarizer(sparse_output=False)\n",
    "    tag_feats = mlb.fit_transform(all_tags)\n",
    "\n",
    "    # description tfidf -> reduce to 50 dims\n",
    "    vect = TfidfVectorizer(max_features=300)\n",
    "    tfidf = vect.fit_transform(descriptions).toarray()\n",
    "    # maybe reduce dimensionality if needed\n",
    "    # combine features\n",
    "    safari_feat = np.hstack([num_feats, tag_feats, tfidf])\n",
    "\n",
    "    # build features for all nodes (safaris then locations)\n",
    "    N = idx\n",
    "    feat_dim = safari_feat.shape[1]\n",
    "    X = np.zeros((N, feat_dim), dtype=np.float32)\n",
    "    for i, key in enumerate(safari_keys):\n",
    "        X[node_index[key]] = safari_feat[i]\n",
    "\n",
    "    # location features: use mean of safaris in location or lat/lon\n",
    "    for loc in location_nodes.keys():\n",
    "        key = f\"LOC:{loc}\"\n",
    "        # compute mean over safaris at that location\n",
    "        saf_idxs = [node_index[f\"SAF:{s.get('id', s['title'])}\"] for s in safari_nodes if s['extracted_features']['district']\n",
    "==loc]\n",
    "        if saf_idxs:\n",
    "            X[node_index[key]] = safari_feat[[i for i,s in enumerate(safari_nodes) if s['extracted_features']['district']\n",
    "==loc]].mean(axis=0)\n",
    "        else:\n",
    "            X[node_index[key]] = np.zeros(feat_dim)\n",
    "\n",
    "    # build edges: safari->location and safari-safari similarity (tag overlap)\n",
    "    edges = []\n",
    "    for s in safari_nodes:\n",
    "        s_key = f\"SAF:{s.get('id', s['title'])}\"\n",
    "        loc_key = f\"LOC:{s['extracted_features']['district']}\"\n",
    "        edges.append((node_index[s_key], node_index[loc_key]))\n",
    "    # safari-safari edges by tag overlap\n",
    "    for i,s1 in enumerate(safari_nodes):\n",
    "        for j,s2 in enumerate(safari_nodes[i+1:], start=i+1):\n",
    "            if set(s1.get('tags',[])) & set(s2.get('tags',[])):\n",
    "                a = node_index[f\"SAF:{s1.get('id', s1['title'])}\"]\n",
    "                b = node_index[f\"SAF:{s2.get('id', s2['title'])}\"]\n",
    "                edges.append((a,b)); edges.append((b,a))\n",
    "\n",
    "    edge_index = torch.tensor(edges, dtype=torch.long).t().contiguous()\n",
    "    X = torch.tensor(X, dtype=torch.float)\n",
    "    data = Data(x=X, edge_index=edge_index)\n",
    "    return data, node_index\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
